# Capitolo 2.

## Lavorare con i dataset

Un'astrazione importante in PyTorch è costituita dai Dataset.
La classe che incapsula un nostro dataset deve:
* estendere la classe torch.utils.data.Dataset
* implementare i due metodi: __len__ e __get_item__

Nel Notebook [prepare_dataset](./prepare_dataset.ipynb) mostro come possiamo incapsulare in un Dataset il caricamento di un file csv ed anche la logica di trasformazione dati, in modo da avere i dati pronti per essere passati in input ad una rete neurale FC implementata in PyTorch.

Il concetto è del tutto generico e vale anche nel caso di immagini, audio, etc: ogni volta che dovremo lavorare con un nostro dataset dovremo scrivere una tale classe implementando i due metodi:
* __len__ e __get_item__

## Items come torch.tensor

PyTorch consente di lavorare e mescolare vettiri numpy e tensori (torch).

Ma, si devono avere presenti alcune fondamentali differenze:
1. I tensory PyTorch possono essere utilizzati anche sulle **GPU** e le operazioni sono eseguite sulle GPU (basta spostare i tesori sulla GPU)
2. Numpy non può lavorare su GPU
3. Se il codice utilizza numpy vi possono essere difficoltà nel momemnto in cui si vuole utilizzare ONNX per la distribuzione (deploy)

Per questi motivi, io penso che, ad esempio se si scrive una classe Dataset custom, si deve fare attenzione a produrre in uscita tensori e non liste o vettori numpy.
Ciò, per quanto concerne l'addestramento del modello, dove vogliamo poter usare le GPU.

Per quanto riguarda l'inferenza, dopo aver prodotto le previsioni (mediante applicazione del modello) possiamo trasformare i risultati in vettori numpy, se utile.

