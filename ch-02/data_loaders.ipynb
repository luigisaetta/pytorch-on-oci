{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0dfe603",
   "metadata": {},
   "source": [
    "### How to: work with Data Loaders\n",
    "\n",
    "How to iterate over the entire dataset using DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ecc0c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Pandas for Data Import from csv\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4528a823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "693bd1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttritionDataset(Dataset):\n",
    "    \"\"\"Oracle Attrition dataset.\"\"\"\n",
    "\n",
    "    # categoricals cols are identified dynamically\n",
    "    # the rule used: each cols with < 10 distinct values\n",
    "    def identify_categoricals(self):\n",
    "        # theshol to identify categoricals cols\n",
    "        THR = 10\n",
    "\n",
    "        nunique = self.df.nunique()\n",
    "        types = self.df.dtypes\n",
    "\n",
    "        self.categorical_columns = []\n",
    "\n",
    "        for col in self.df.columns:\n",
    "            # identifichiamo come categoriche tutte le colonne che soddisfano questa condizione\n",
    "            # la soglia THR la possiamo cambiare\n",
    "            if types[col] == \"object\" or nunique[col] < THR:\n",
    "                if DEBUG:\n",
    "                    print(f\"{col} distinct values: {self.df[col].nunique()}\")\n",
    "\n",
    "                self.categorical_columns.append(col)\n",
    "\n",
    "    def codify_categoricals(self):\n",
    "        for col in self.categorical_columns:\n",
    "            # codifichiamo i categorici con LabelEncoder\n",
    "            l_enc = LabelEncoder()\n",
    "            self.df[col] = l_enc.fit_transform(self.df[col].values)\n",
    "\n",
    "    \"\"\"\n",
    "    In __init__ we encapsulate the logic for loading the data from csv\n",
    "    remove unneeded cols\n",
    "    identify categoricals\n",
    "    codify as integer, using LabelEncoder categoricals\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, csv_file):\n",
    "        \"\"\"Initializes instance of class AttritionDataset.\n",
    "\n",
    "        Args:\n",
    "            csv_file (str): Path to the csv file with the data.\n",
    "\n",
    "        \"\"\"\n",
    "        # here we read the entire csv\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "\n",
    "        # cols not to be used\n",
    "        self.cols_to_drop = [\n",
    "            \"Directs\",\n",
    "            \"name\",\n",
    "            \"Over18\",\n",
    "            \"WeeklyWorkedHours\",\n",
    "            \"EmployeeNumber\",\n",
    "        ]\n",
    "\n",
    "        self.target = \"Attrition\"\n",
    "\n",
    "        # dropping cols not to be used\n",
    "        self.df = self.df.drop(columns=self.cols_to_drop)\n",
    "\n",
    "        # label encoding of categoricals\n",
    "        self.identify_categoricals()\n",
    "        self.codify_categoricals()\n",
    "\n",
    "        # Save features and target as tensors\n",
    "        self.X = torch.from_numpy(self.df.drop(self.target, axis=1).values)\n",
    "        self.y = torch.from_numpy(self.df[self.target].values)\n",
    "\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset has two fundamentals methods\n",
    "    __len__ which must return the number of records in the dataset\n",
    "    __get_item must return item of index idx as a Tensor\n",
    "    \"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Convert idx from tensor to list due to pandas bug (that arises when using pytorch's random_split)\n",
    "        # if isinstance(idx, torch.Tensor):\n",
    "        #    idx = idx.tolist()\n",
    "\n",
    "        return (self.X[idx], self.y[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3568550",
   "metadata": {},
   "source": [
    "#### Build the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bff01384",
   "metadata": {},
   "outputs": [],
   "source": [
    "attrition_path = \"/opt/notebooks/ads-examples/oracle_data/orcl_attrition.csv\"\n",
    "\n",
    "attrition_ds = AttritionDataset(attrition_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55531d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Build the DataLOader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "724cb400",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataloader = DataLoader(attrition_ds, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e28a34f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a0b0416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 30])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4a9a8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 98.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([62, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([62, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([62, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([62, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([62, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([62, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([62, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([62, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([62, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([64, 30])\n",
      "torch.Size([62, 30])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# one epoch: iterate over entire dataset\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    for batch in train_dataloader:\n",
    "        train_features, train_labels = batch\n",
    "        \n",
    "        # do something\n",
    "        # print(train_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119cb553",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch110_p37_gpu_v1]",
   "language": "python",
   "name": "conda-env-pytorch110_p37_gpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
