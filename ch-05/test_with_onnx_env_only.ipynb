{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9c40269",
   "metadata": {},
   "source": [
    "### Test PyTorch Convolutional Network using ONNX conda env\n",
    "\n",
    "In this second example on using ONNX together with PyTorch and PyTorch Lightning, we see as the **deployment is really easy**.\n",
    "\n",
    "1. Actually, as soon as we have the model deployed in ONNX format, we don't need the code of the Lightning Module\n",
    "2. We only need an environment with the ONNX runtime\n",
    "3. torchvision here is used only to have quick access to images amd implment the needed tranforms\n",
    "\n",
    "\n",
    "This NB can be run inside ONNX 1.10 for CPU on Python 3.7 conda env.\n",
    "\n",
    "You need to install only torch and torchvision to have quick access to MNIST images and transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d37cde85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "import onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ac596bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# where we're storing the downloaded dataset\n",
    "PATH_DATASETS = \".\"\n",
    "\n",
    "ONNX_FILE = \"light_cnn.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cba6234a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need an input sample to save in onnx format\n",
    "\n",
    "# the definition of transforms over images\n",
    "img_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        # normalization is clarified here\n",
    "        # https://discuss.pytorch.org/t/normalization-in-the-mnist-example/457\n",
    "        transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# we take an input image from the dataset\n",
    "# when we load the dataset we apply transforms as expected from the model\n",
    "mnist_test = MNIST(\".\", train=False, download=True, transform=img_transforms)\n",
    "\n",
    "# index of the image for the test\n",
    "INDEX = 10\n",
    "\n",
    "# take a sample\n",
    "img_tensor, label = mnist_test[INDEX]\n",
    "\n",
    "# make it a batch\n",
    "input_batch = img_tensor.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e66fada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only at setup\n",
    "ort_session = onnxruntime.InferenceSession(ONNX_FILE)\n",
    "\n",
    "input_name = ort_session.get_inputs()[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eacd1a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted label is: 0, expected label is: 0\n"
     ]
    }
   ],
   "source": [
    "# as input you need to pass a np array, not torch tensor\n",
    "# otherwise it wouldn't be... independent from the framework !\n",
    "ort_inputs = {input_name: input_batch.numpy()}\n",
    "\n",
    "out_class = np.argmax(ort_session.run(None, ort_inputs))\n",
    "\n",
    "print()\n",
    "print(f\"Predicted label is: {out_class}, expected label is: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89876914",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:onnx110_p37_cpu_v1]",
   "language": "python",
   "name": "conda-env-onnx110_p37_cpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
