{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8007a479",
   "metadata": {},
   "source": [
    "### Cloud Classifier based on PyTorch Lightning\n",
    "\n",
    "dataset used from: https://www.kaggle.com/competitions/cloud-type-classification2\n",
    "\n",
    "To execute the notebook you need to download the dataset, from the kaggle competition site, with the command:\n",
    "\n",
    "kaggle competitions download -c cloud-type-classification2\n",
    "\n",
    "and unzip the downloaded file in $BASE_DIR\n",
    "\n",
    "In this NB we use EffNetB2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b8c5b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "# the backbone\n",
    "from torchvision.models import efficientnet_b2\n",
    "\n",
    "sns.set()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75aa4b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "\n",
    "# for train dataloader.\n",
    "NUM_WORKERS = 12\n",
    "\n",
    "# size of the image we're working on for EffNetB2\n",
    "IMAGE_SIDE = 260\n",
    "\n",
    "# the base_dir inside which we unzip the file from Kaggle\n",
    "BASE_DIR = \"/home/datascience/clouds_classification_data/\"\n",
    "\n",
    "IMAGES_TRAIN = path.join(BASE_DIR, \"images/train/\")\n",
    "IMAGES_TEST = path.join(BASE_DIR, \"images/test/\")\n",
    "\n",
    "# the file with image_name, label\n",
    "FILE_TRAIN = path.join(BASE_DIR, \"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3454dfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we read the csv with all file name + labes\n",
    "train_csv_df = pd.read_csv(FILE_TRAIN)\n",
    "\n",
    "# count the number of classes\n",
    "# cirriform clouds,high cumuliform clouds,stratocumulus clouds,cumulus clouds,cumulonimbus clouds,stratiform clouds,clear sky\n",
    "N_CLASSES = train_csv_df['label'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f51b2bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of classes is: 7\n"
     ]
    }
   ],
   "source": [
    "print(f\"The number of classes is: {N_CLASSES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0aceb89",
   "metadata": {},
   "source": [
    "#### Image trasformations (also for augmentation, applied only to train set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77a8b061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm using mean and std for ImageNet\n",
    "MEANS = [0.485, 0.456, 0.406]\n",
    "STDS = [0.229, 0.224, 0.225]\n",
    "\n",
    "# removed vertical flip, some clouds are recognized from what is on top\n",
    "def get_train_transform():\n",
    "    return T.Compose(\n",
    "        [\n",
    "            T.Resize((IMAGE_SIDE, IMAGE_SIDE)),\n",
    "            T.RandomHorizontalFlip(p=0.5),\n",
    "            T.RandomRotation(25),\n",
    "            T.RandomAdjustSharpness(sharpness_factor=1.5, p=0.3),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=MEANS, std=STDS),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# val transforms doesn't make augmentation: we want to validate every time\n",
    "# on the same images\n",
    "def get_val_transform():\n",
    "    return T.Compose(\n",
    "        [\n",
    "            T.Resize((IMAGE_SIDE, IMAGE_SIDE)),\n",
    "            T.ToTensor(), \n",
    "            T.Normalize(mean=MEANS, std=STDS)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2eda418",
   "metadata": {},
   "source": [
    "#### The custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d8dd722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass as input the train dataframe\n",
    "class CloudsDataset(Dataset):\n",
    "    def __init__(self, df, transforms=None):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        # list with imgs names\n",
    "        self.imgs = df['id'].values\n",
    "        self.labels = df['label'].values\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        full_image_name = path.join(IMAGES_TRAIN, self.imgs[idx])\n",
    "        \n",
    "        img = Image.open(full_image_name)\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        # get the label\n",
    "        label = self.labels[idx]\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        \n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52bc8f7",
   "metadata": {},
   "source": [
    "#### Datasets and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "470e4594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/validation split:\n",
      "We have 864 imgs for training\n",
      "We have 96 imgs for validation\n"
     ]
    }
   ],
   "source": [
    "# split in train and validation\n",
    "# added shuffling (LS, 9/11/2022)\n",
    "\n",
    "# the dataset is small, I'm using only 10% for validation\n",
    "VAL_FRAC = 0.1\n",
    "\n",
    "train_df_used, val_df_used = train_test_split(train_csv_df, shuffle= True, test_size=VAL_FRAC)\n",
    "\n",
    "print(\"Train/validation split:\")\n",
    "print(f\"We have {len(train_df_used)} imgs for training\")\n",
    "print(f\"We have {len(val_df_used)} imgs for validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ea4a7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets\n",
    "train_ds = CloudsDataset(train_df_used, transforms=get_train_transform())\n",
    "val_ds = CloudsDataset(val_df_used, transforms=get_val_transform())\n",
    "\n",
    "# data loaders\n",
    "train_dl = DataLoader(\n",
    "    dataset=train_ds, num_workers=NUM_WORKERS, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True\n",
    ")\n",
    "\n",
    "val_dl = DataLoader(\n",
    "    dataset=val_ds, num_workers=NUM_WORKERS, batch_size=BATCH_SIZE, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89723cda",
   "metadata": {},
   "source": [
    "#### The Lightning Model based on EffNetB2\n",
    "\n",
    "we're using the EffNetB2 from TorchVision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39f52754",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitCloudClassifierB2(LightningModule):\n",
    "    def __init__(self, learning_rate=0.0001):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # Set our init args as class attributes\n",
    "        self.lr = learning_rate\n",
    "\n",
    "        # dataset specific attributes\n",
    "        self.num_classes = N_CLASSES\n",
    "        \n",
    "        # Define PyTorch model: a simple CNN\n",
    "        self.model = efficientnet_b2(pretrained=True)\n",
    "        # changed to 1408 for B2\n",
    "        self.model.classifier[1] = nn.Sequential(nn.Linear(1408, self.num_classes, bias=True))\n",
    "\n",
    "        self.val_accuracy = Accuracy()\n",
    "        self.test_accuracy = Accuracy()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # the model outputs logits not probabilities\n",
    "        # this is better for numerical stability\n",
    "        x = self.model(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.val_accuracy.update(preds, y)\n",
    "\n",
    "        # Calling self.log will surface up scalars for you in TensorBoard\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", self.val_accuracy, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.test_accuracy.update(preds, y)\n",
    "\n",
    "        # Calling self.log will surface up scalars for you in TensorBoard\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "        self.log(\"test_acc\", self.test_accuracy, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # for now fixed LR\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        \n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46baf647",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(dirpath=\"checkpoint_clouds\", save_top_k=1, monitor=\"val_loss\",\n",
    "                                     mode=\"min\",\n",
    "                                     filename=\"clouds-{epoch:02d}-{val_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85a574f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "model = LitCloudClassifierB2()\n",
    "\n",
    "trainer = Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    # we can choose to use mixed precision, to reduce mem. footprint\n",
    "    precision=16,\n",
    "    devices=1 if torch.cuda.is_available() else None,\n",
    "    max_epochs=EPOCHS,\n",
    "    callbacks=[TQDMProgressBar(refresh_rate=5), checkpoint_callback],\n",
    "    logger=CSVLogger(save_dir=\"logs/\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d532a3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/datascience/conda/computervision_p37_gpu_v1/lib/python3.7/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:616: UserWarning: Checkpoint directory /home/datascience/pytorch-on-oci/ch-04/checkpoint_clouds exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type         | Params\n",
      "-----------------------------------------------\n",
      "0 | model         | EfficientNet | 7.7 M \n",
      "1 | val_accuracy  | Accuracy     | 0     \n",
      "2 | test_accuracy | Accuracy     | 0     \n",
      "-----------------------------------------------\n",
      "7.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.7 M     Total params\n",
      "15.422    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ffd3e6b942446eaa48e7408a4528e9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_dl, val_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acbe9f1",
   "metadata": {},
   "source": [
    "#### Plot metrics during the epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7a12601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 442.85x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get metrics from the logs\n",
    "metrics = pd.read_csv(f\"{trainer.logger.log_dir}/metrics.csv\")\n",
    "del metrics[\"step\"]\n",
    "metrics.set_index(\"epoch\", inplace=True)\n",
    "\n",
    "# if you want also in tabular format\n",
    "# display(metrics.dropna(axis=1, how=\"all\").tail(10))\n",
    "\n",
    "sns.relplot(data=metrics, kind=\"line\").set(title='Metrics for val set');\n",
    "plt.grid(True)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f53f4c3",
   "metadata": {},
   "source": [
    "#### Test: reload the Best Model and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f21736d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put here the name of the best checkpoint file\n",
    "model = LitCloudClassifierB2.load_from_checkpoint(\"./checkpoint_clouds/bestb205022023.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6fac691",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ca637eb871645b9a2af7401f2d8f43f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc                  0.9375\n",
      "        test_loss           0.14069868624210358\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.14069868624210358, 'test_acc': 0.9375}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, val_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4636b418",
   "metadata": {},
   "source": [
    "#### let's see the errors on the entire validation set\n",
    "\n",
    "could be improved using batch, but since val_set is small it is ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cb150f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/96 [00:00<00:24,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: 1, predicted: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 28/96 [00:08<00:20,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: 1, predicted: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 59/96 [00:16<00:09,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: 2, predicted: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 66/96 [00:17<00:07,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: 2, predicted: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 68/96 [00:18<00:08,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: 1, predicted: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 79/96 [00:21<00:04,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: 1, predicted: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 81/96 [00:22<00:03,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: 3, predicted: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [00:25<00:00,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tot. OK: 89 over: 96\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_test = len(val_ds)\n",
    "n_ok = 0\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "for i in tqdm(range(n_test)):\n",
    "    img, label = val_ds[i]\n",
    "\n",
    "    img_batch = img.unsqueeze(0)\n",
    "    img_batch = img_batch.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        preds = model(img_batch)\n",
    "\n",
    "    class_predicted = torch.argmax(preds, dim=1)\n",
    "    \n",
    "    # otherwise are tensors\n",
    "    label = label.item()\n",
    "    class_predicted = class_predicted.item()\n",
    "    \n",
    "    if class_predicted == label:\n",
    "        n_ok += 1\n",
    "    else:\n",
    "        print(f\"Expected: {label}, predicted: {class_predicted}\")\n",
    "        \n",
    "print()\n",
    "print(f\"Tot. OK: {n_ok} over: {n_test}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2624f1b9",
   "metadata": {},
   "source": [
    "#### Prepare Submission for Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3dce02",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_TEST = BASE_DIR +\"images/test/\"\n",
    "FILE_TEST = BASE_DIR + \"test.csv\"\n",
    "\n",
    "test_df = pd.read_csv(FILE_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9aa33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs = list(test_df['id'].values)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464f4c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### here we create a custom dataset for test (no labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f02672d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CloudsTestDataset(Dataset):\n",
    "    def __init__(self, df, transforms=None):\n",
    "        super().__init__()\n",
    "        # list with imgs names\n",
    "        self.imgs = df['id'].values\n",
    "        self.df = df\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        full_image_name = IMAGES_TEST + self.imgs[idx]\n",
    "        \n",
    "        img = Image.open(full_image_name)\n",
    "        # OK for EfficientNet B0\n",
    "        # if scaling to another EffNet change the size here!\n",
    "        img = self.transforms(img)\n",
    "        \n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7553c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = CloudsTestDataset(test_df, transforms=get_val_transform())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dccd60f",
   "metadata": {},
   "source": [
    "#### Predictions for all test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42117e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "list_preds = []\n",
    "\n",
    "for i in tqdm(range(len(test_ds))):\n",
    "    img = test_ds[i]\n",
    "\n",
    "    img_batch = img.unsqueeze(0)\n",
    "    img_batch = img_batch.to(device)\n",
    "    \n",
    "    preds = model(img_batch)\n",
    "\n",
    "    class_predicted = torch.argmax(preds)\n",
    "    class_predicted = class_predicted.item()\n",
    "    \n",
    "    list_preds.append(class_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1af507e",
   "metadata": {},
   "source": [
    "#### Get a file with the class_num for each jpg image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a3a85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_sub = {\"id\": test_imgs, \n",
    "           \"predict\": list_preds}\n",
    "\n",
    "df_sub = pd.DataFrame(dict_sub)\n",
    "\n",
    "df_sub.to_csv(\"submit04.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a41a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:computervision_p37_gpu_v1]",
   "language": "python",
   "name": "conda-env-computervision_p37_gpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
