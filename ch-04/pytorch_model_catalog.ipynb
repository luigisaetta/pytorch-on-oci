{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02d83cf5",
   "metadata": {},
   "source": [
    "### Save the MNIST Model to Model Catalog\n",
    "\n",
    "In this NB we go through the entire deployment life-cycle. \n",
    "\n",
    "We start from a trained model, we save it in the Model Catalog and then we deploy it as a REST service.\n",
    "\n",
    "Finally, we test it with some samples images.\n",
    "\n",
    "* (23/12/2023): the NB has been ported to using A10; Added shape_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b58ee9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchmetrics import Accuracy\n",
    "from torchvision import transforms\n",
    "\n",
    "from pytorch_lightning import LightningModule\n",
    "\n",
    "# from here we get MNIST dataset\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "import ads\n",
    "from ads import set_auth\n",
    "from ads.common.model_metadata import UseCaseType, MetadataCustomCategory\n",
    "from ads.model.framework.pytorch_model import PyTorchModel\n",
    "\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0a18d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.6\n"
     ]
    }
   ],
   "source": [
    "print(ads.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d42ca8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# where we're storing the downloaded dataset\n",
    "PATH_DATASETS = \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75f4d0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need the class to load the model after\n",
    "class LitMNISTCNN(LightningModule):\n",
    "    def __init__(self, data_dir=PATH_DATASETS, learning_rate=2e-4):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # Set our init args as class attributes\n",
    "        self.data_dir = data_dir\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # dataset specific attributes\n",
    "        self.num_classes = 10\n",
    "        # shape of input images in MNIST\n",
    "        self.dims = (1, 28, 28)\n",
    "        channels, width, height = self.dims\n",
    "        \n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                # normalization is clarified here\n",
    "                # https://discuss.pytorch.org/t/normalization-in-the-mnist-example/457\n",
    "                transforms.Normalize((0.1307,), (0.3081,)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Define PyTorch model: a simple CNN\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=5),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv2d(32, 64, kernel_size=5),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3*3*64, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(256, self.num_classes),\n",
    "        )\n",
    "\n",
    "        self.val_accuracy = Accuracy()\n",
    "        self.test_accuracy = Accuracy()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # the model outputs logits not probabilities\n",
    "        # this is better for numerical stability\n",
    "        x = self.model(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.val_accuracy.update(preds, y)\n",
    "\n",
    "        # Calling self.log will surface up scalars for you in TensorBoard\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", self.val_accuracy, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.test_accuracy.update(preds, y)\n",
    "\n",
    "        # Calling self.log will surface up scalars for you in TensorBoard\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "        self.log(\"test_acc\", self.test_accuracy, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "    \n",
    "    # we can remove the dataloader part here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e0560d",
   "metadata": {},
   "source": [
    "#### Reload the model from a checkpoint and prepare to save to Model Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05db88ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitMNISTCNN.load_from_checkpoint(\"./checkpoint_mnist/best.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "093b7dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LitMNISTCNN(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): ReLU()\n",
       "    (9): Dropout(p=0.5, inplace=False)\n",
       "    (10): Flatten(start_dim=1, end_dim=-1)\n",
       "    (11): Linear(in_features=576, out_features=256, bias=True)\n",
       "    (12): ReLU()\n",
       "    (13): Dropout(p=0.1, inplace=False)\n",
       "    (14): Linear(in_features=256, out_features=10, bias=True)\n",
       "  )\n",
       "  (val_accuracy): Accuracy()\n",
       "  (test_accuracy): Accuracy()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the summary of CNN architecture\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9aa6af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:ads.common:In the future model input will be serialized by `cloudpickle` by default. Currently, model input are serialized into a dictionary containing serialized input data and original data type information.Set `model_input_serializer=\"cloudpickle\"` to use cloudpickle model input serializer.\n"
     ]
    }
   ],
   "source": [
    "# set RP\n",
    "set_auth(auth='resource_principal')\n",
    "\n",
    "artifact_dir = \"pytorch_artifact_dir\"\n",
    "\n",
    "pytorch_model = PyTorchModel(model, artifact_dir=artifact_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96b44e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/home/datascience/conda/pytorch_onoci_v1_0/lib/python3.8/site-packages/ads/model/runtime/env_info.py:92: UserWarning: slug will be deprecated. Provide conda pack path instead.                                    ?, ?it/s]\n",
      "  warnings.warn(\"slug will be deprecated. Provide conda pack path instead.\")\n",
      "\n",
      "WARNING:ads.common:In future the models will be saved in TorchScript format by default. Currently saving it using torch.save method.Set `use_torch_script` as `True` to serialize the model as a TorchScript program by `torch.jit.save()` and loaded using `torch.jit.load()` in score.py. You don't need to modify `load_model()` in score.py to load the model.Check https://pytorch.org/tutorials/beginner/saving_loading_models.html#export-load-model-in-torchscript-format for more details.Set `use_torch_script` as `False` to save only the model parameters.The model class instance must be constructed before loading parameters in the perdict function of score.py.Check https://pytorch.org/tutorials/beginner/saving_loading_models.html#save-load-state-dict-recommended for more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "algorithm: LitMNISTCNN\n",
       "artifact_dir:\n",
       "  /home/datascience/pytorch-on-oci/ch-04/pytorch_artifact_dir:\n",
       "  - - score.py\n",
       "    - saved_score-Copy1.py\n",
       "    - test_json_output.json\n",
       "    - model.pt\n",
       "    - runtime.yaml\n",
       "    - .model-ignore\n",
       "framework: pytorch\n",
       "model_deployment_id: null\n",
       "model_id: null"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# switched the inference env to a published conda env\n",
    "# being a published env I need to pass the object storage path\n",
    "\n",
    "# this is the path of OSS wehere we have saved the published env\n",
    "INF_ENV_PATH = \"oci://custom_conda_envs@frqap2zhtzbe/conda_environments/gpu/mycomputervision_p37_gpu_/1.0/mycomputervision_p37_gpu_v1_0\"\n",
    "\n",
    "pytorch_model.prepare(\n",
    "    inference_conda_env=INF_ENV_PATH,\n",
    "    training_conda_env=\"computervision_p37_cpu_v1\",\n",
    "    use_case_type=UseCaseType.IMAGE_CLASSIFICATION,\n",
    "    force_overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4a21e3",
   "metadata": {},
   "source": [
    "after the prepare you need to cancel model.pt, **copy best.ckpt** to pytorch_attifact_dir and rename to model.pt\n",
    "\n",
    "This is related to using Lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4595ffe0",
   "metadata": {},
   "source": [
    "#### correctly setting some metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad45d99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the correct name of the model file name\n",
    "pytorch_model.metadata_custom['ModelFileName'].update(value=\"model.pt\", category=MetadataCustomCategory.OTHER, description=\"model file name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "046a07c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_model.metadata_custom['ModelArtifacts'].update(value=\"score.py, model.pt, runtime.yaml\", \n",
    "                                                       category=MetadataCustomCategory.TRAINING_ENV, \n",
    "                                                       description=\"The list of files located in artifacts folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0274c750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data:\n",
       "- category: Other\n",
       "  description: ''\n",
       "  key: ClientLibrary\n",
       "  value: ADS\n",
       "- category: Training Environment\n",
       "  description: The URI of the training conda environment.\n",
       "  key: CondaEnvironmentPath\n",
       "  value: oci://service-conda-packs@id19sfcrra6z/service_pack/cpu/Computer_Vision_for_CPU_on_Python_3.7/1.0/computervision_p37_cpu_v1\n",
       "- category: Training Environment\n",
       "  description: The list of files located in artifacts folder.\n",
       "  key: ModelArtifacts\n",
       "  value: score.py, model.pt, runtime.yaml\n",
       "- category: Training Profile\n",
       "  description: The model serialization format.\n",
       "  key: ModelSerializationFormat\n",
       "  value: pt\n",
       "- category: Training Environment\n",
       "  description: The conda environment type, can be published or datascience.\n",
       "  key: EnvironmentType\n",
       "  value: data_science\n",
       "- category: Training Environment\n",
       "  description: The conda environment where the model was trained.\n",
       "  key: CondaEnvironment\n",
       "  value: oci://service-conda-packs@id19sfcrra6z/service_pack/cpu/Computer_Vision_for_CPU_on_Python_3.7/1.0/computervision_p37_cpu_v1\n",
       "- category: Training Environment\n",
       "  description: The slug name of the training conda environment.\n",
       "  key: SlugName\n",
       "  value: computervision_p37_cpu_v1\n",
       "- category: Other\n",
       "  description: model file name\n",
       "  key: ModelFileName\n",
       "  value: model.pt"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_model.metadata_custom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32de0ac",
   "metadata": {},
   "source": [
    "#### Finally save the model to Model Catalog\n",
    "\n",
    "before running this you must modify the file score.py to load successfully the model\n",
    "\n",
    "from \n",
    "\n",
    "/home/datascience/pytorch-on-oci/ch-04/checkpoint_mnist dir \n",
    "\n",
    "exec command:\n",
    "\n",
    "cp best.ckpt ../pytorch_artifact_dir/model.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e6350e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading model.pt from model directory /home/datascience/pytorch-on-oci/ch-04/pytorch_artifact_dir ...\n",
      "loading model.pt is complete.\n",
      "Model is successfully loaded.\n",
      "['score.py', 'saved_score-Copy1.py', 'test_json_output.json', 'model.pt', 'runtime.yaml', '.model-ignore']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loop1:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_NAME = \"pytorch-mnist12\"\n",
    "\n",
    "model_id = pytorch_model.save(display_name=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08e1a920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Actions Needed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Step</th>\n",
       "      <th>Status</th>\n",
       "      <th>Details</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>initiate</th>\n",
       "      <th>Done</th>\n",
       "      <th>Initiated the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">prepare()</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">Done</th>\n",
       "      <th>Generated runtime.yaml</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Generated score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Serialized model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Populated metadata(Custom, Taxonomy and Provenance)</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verify()</th>\n",
       "      <th>Available</th>\n",
       "      <th>Local tested .predict from score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">save()</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Done</th>\n",
       "      <th>Conducted Introspect Test</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uploaded artifact to model catalog</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deploy()</th>\n",
       "      <th>UNKNOWN</th>\n",
       "      <th>Deployed the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict()</th>\n",
       "      <th>Not Available</th>\n",
       "      <th>Called deployment predict endpoint</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            Actions Needed\n",
       "Step      Status        Details                                                           \n",
       "initiate  Done          Initiated the model                                               \n",
       "prepare() Done          Generated runtime.yaml                                            \n",
       "                        Generated score.py                                                \n",
       "                        Serialized model                                                  \n",
       "                        Populated metadata(Custom, Taxonomy and Provenance)               \n",
       "verify()  Available     Local tested .predict from score.py                               \n",
       "save()    Done          Conducted Introspect Test                                         \n",
       "                        Uploaded artifact to model catalog                                \n",
       "deploy()  UNKNOWN       Deployed the model                                                \n",
       "predict() Not Available Called deployment predict endpoint                                "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_model.summary_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43bb87b",
   "metadata": {},
   "source": [
    "#### Test locally the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c707f93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we take an input image from the dataset\n",
    "# when we load the dataset we apply transforms as expected from the model\n",
    "mnist_test = MNIST(\".\", train=False, transform=model.transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48458e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "\n",
      "Expected label is: 0\n"
     ]
    }
   ],
   "source": [
    "INDEX = 10\n",
    "\n",
    "# take a sample\n",
    "img_tensor, label = mnist_test[INDEX]\n",
    "\n",
    "print(img_tensor.shape)\n",
    "print()\n",
    "print(f\"Expected label is: {label}\")\n",
    "\n",
    "# make it a batch\n",
    "input_batch = img_tensor.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ab9b02",
   "metadata": {},
   "source": [
    "#### Call the model and predict the label from the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37db3297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading model.pt from model directory /home/datascience/pytorch-on-oci/ch-04/pytorch_artifact_dir ...\n",
      "loading model.pt is complete.\n",
      "Model is successfully loaded.\n",
      "\n",
      "Predicted label is: 0\n"
     ]
    }
   ],
   "source": [
    "prediction = pytorch_model.verify(input_batch)[\"prediction\"]\n",
    "\n",
    "print()\n",
    "print(f\"Predicted label is: {np.argmax(prediction)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ab0d5fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Actions Needed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Step</th>\n",
       "      <th>Status</th>\n",
       "      <th>Details</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>initiate</th>\n",
       "      <th>Done</th>\n",
       "      <th>Initiated the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">prepare()</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">Done</th>\n",
       "      <th>Generated runtime.yaml</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Generated score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Serialized model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Populated metadata(Custom, Taxonomy and Provenance)</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verify()</th>\n",
       "      <th>Done</th>\n",
       "      <th>Local tested .predict from score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">save()</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Done</th>\n",
       "      <th>Conducted Introspect Test</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uploaded artifact to model catalog</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deploy()</th>\n",
       "      <th>UNKNOWN</th>\n",
       "      <th>Deployed the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict()</th>\n",
       "      <th>Not Available</th>\n",
       "      <th>Called deployment predict endpoint</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            Actions Needed\n",
       "Step      Status        Details                                                           \n",
       "initiate  Done          Initiated the model                                               \n",
       "prepare() Done          Generated runtime.yaml                                            \n",
       "                        Generated score.py                                                \n",
       "                        Serialized model                                                  \n",
       "                        Populated metadata(Custom, Taxonomy and Provenance)               \n",
       "verify()  Done          Local tested .predict from score.py                               \n",
       "save()    Done          Conducted Introspect Test                                         \n",
       "                        Uploaded artifact to model catalog                                \n",
       "deploy()  UNKNOWN       Deployed the model                                                \n",
       "predict() Not Available Called deployment predict endpoint                                "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_model.summary_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03762e59",
   "metadata": {},
   "source": [
    "#### Ready for Model Deployment\n",
    "\n",
    "at this point we're ready to deploy a model as a REST service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c906a999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loop1:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "kind: deployment\n",
       "spec:\n",
       "  createdBy: ocid1.datasciencenotebooksession.oc1.eu-frankfurt-1.amaaaaaangencdya4yfx56nsh3qau7o2y2mrq3er37tpi6w7yy3bgoihnjga\n",
       "  definedTags:\n",
       "    default-tags:\n",
       "      CreatedBy: ocid1.datasciencenotebooksession.oc1.eu-frankfurt-1.amaaaaaangencdya4yfx56nsh3qau7o2y2mrq3er37tpi6w7yy3bgoihnjga\n",
       "  displayName: MNIST Model For Classification ver 12\n",
       "  id: ocid1.datasciencemodeldeployment.oc1.eu-frankfurt-1.amaaaaaangencdyagaakxrml5rxqtrdyhwghzpfwdh64q72snegcydyqrq7a\n",
       "  infrastructure:\n",
       "    kind: infrastructure\n",
       "    spec:\n",
       "      accessLog:\n",
       "        logGroupId: ocid1.loggroup.oc1.eu-frankfurt-1.amaaaaaangencdya63i3qhao4bjx754lb3m2jpekev5oc55p5ebjvykbtgya\n",
       "        logId: ocid1.log.oc1.eu-frankfurt-1.amaaaaaangencdyamg6gyfdjofod7hlnbhhjtgeaeyy3fkrmh3cyb4dxx7xa\n",
       "      bandwidthMbps: 10\n",
       "      compartmentId: ocid1.compartment.oc1..aaaaaaaag2cpni5qj6li5ny6ehuahhepbpveopobooayqfeudqygdtfe6h3a\n",
       "      deploymentType: SINGLE_MODEL\n",
       "      policyType: FIXED_SIZE\n",
       "      predictLog:\n",
       "        logGroupId: ocid1.loggroup.oc1.eu-frankfurt-1.amaaaaaangencdya63i3qhao4bjx754lb3m2jpekev5oc55p5ebjvykbtgya\n",
       "        logId: ocid1.log.oc1.eu-frankfurt-1.amaaaaaangencdyaddqi3rff7kdbxhxdpi2rx65dynuye36dayz7nivbwsca\n",
       "      projectId: ocid1.datascienceproject.oc1.eu-frankfurt-1.amaaaaaangencdyaxvkmnt7lrhgmiwt6w5h2jvcefu6e6hu7b4leb56mx6kq\n",
       "      replica: 1\n",
       "      shapeName: VM.GPU.A10.1\n",
       "      webConcurrency: '10'\n",
       "    type: datascienceModelDeployment\n",
       "  lifecycleDetails: Model Deployment is Active.\n",
       "  lifecycleState: ACTIVE\n",
       "  modelDeploymentUrl: https://modeldeployment.eu-frankfurt-1.oci.customer-oci.com/ocid1.datasciencemodeldeployment.oc1.eu-frankfurt-1.amaaaaaangencdyagaakxrml5rxqtrdyhwghzpfwdh64q72snegcydyqrq7a\n",
       "  runtime:\n",
       "    kind: runtime\n",
       "    spec:\n",
       "      env:\n",
       "        WEB_CONCURRENCY: '10'\n",
       "      modelUri: ocid1.datasciencemodel.oc1.eu-frankfurt-1.amaaaaaangencdyaivhpu7vfcstvjezib7c2qvuqlubxghoyczznqneh5z2a\n",
       "    type: conda\n",
       "  timeCreated: 2023-06-23 10:15:17.084000+00:00\n",
       "type: modelDeployment"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instance shape: be careful, if the model has been trained on GPU, it must be deployed on a GPU shape\n",
    "# otherwise you get an error when creating model deployment<\n",
    "\n",
    "pytorch_model.deploy(display_name=\"MNIST Model For Classification ver 12\",\n",
    "                     deployment_instance_shape = \"VM.GPU.A10.1\",\n",
    "                     deployment_log_group_id=\"ocid1.loggroup.oc1.eu-frankfurt-1.amaaaaaangencdya63i3qhao4bjx754lb3m2jpekev5oc55p5ebjvykbtgya\",\n",
    "                     deployment_access_log_id=\"ocid1.log.oc1.eu-frankfurt-1.amaaaaaangencdyamg6gyfdjofod7hlnbhhjtgeaeyy3fkrmh3cyb4dxx7xa\",\n",
    "                     deployment_predict_log_id=\"ocid1.log.oc1.eu-frankfurt-1.amaaaaaangencdyaddqi3rff7kdbxhxdpi2rx65dynuye36dayz7nivbwsca\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77d66aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Actions Needed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Step</th>\n",
       "      <th>Status</th>\n",
       "      <th>Details</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>initiate</th>\n",
       "      <th>Done</th>\n",
       "      <th>Initiated the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">prepare()</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">Done</th>\n",
       "      <th>Generated runtime.yaml</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Generated score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Serialized model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Populated metadata(Custom, Taxonomy and Provenance)</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verify()</th>\n",
       "      <th>Done</th>\n",
       "      <th>Local tested .predict from score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">save()</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Done</th>\n",
       "      <th>Conducted Introspect Test</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uploaded artifact to model catalog</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deploy()</th>\n",
       "      <th>ACTIVE</th>\n",
       "      <th>Deployed the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict()</th>\n",
       "      <th>Available</th>\n",
       "      <th>Called deployment predict endpoint</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        Actions Needed\n",
       "Step      Status    Details                                                           \n",
       "initiate  Done      Initiated the model                                               \n",
       "prepare() Done      Generated runtime.yaml                                            \n",
       "                    Generated score.py                                                \n",
       "                    Serialized model                                                  \n",
       "                    Populated metadata(Custom, Taxonomy and Provenance)               \n",
       "verify()  Done      Local tested .predict from score.py                               \n",
       "save()    Done      Conducted Introspect Test                                         \n",
       "                    Uploaded artifact to model catalog                                \n",
       "deploy()  ACTIVE    Deployed the model                                                \n",
       "predict() Available Called deployment predict endpoint                                "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_model.summary_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e776fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://modeldeployment.eu-frankfurt-1.oci.customer-oci.com/ocid1.datasciencemodeldeployment.oc1.eu-frankfurt-1.amaaaaaangencdyagaakxrml5rxqtrdyhwghzpfwdh64q72snegcydyqrq7a'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this way we get the URL of the service\n",
    "pytorch_model.model_deployment.url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7695663",
   "metadata": {},
   "source": [
    "#### Test the deployed endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81072c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted label is: 0\n"
     ]
    }
   ],
   "source": [
    "prediction = pytorch_model.predict(input_batch)[\"prediction\"]\n",
    "print()\n",
    "print(f\"Predicted label is: {np.argmax(prediction)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75eb2a13",
   "metadata": {},
   "source": [
    "#### Final check of the status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6810bbf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Actions Needed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Step</th>\n",
       "      <th>Status</th>\n",
       "      <th>Details</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>initiate</th>\n",
       "      <th>Done</th>\n",
       "      <th>Initiated the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">prepare()</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">Done</th>\n",
       "      <th>Generated runtime.yaml</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Generated score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Serialized model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Populated metadata(Custom, Taxonomy and Provenance)</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verify()</th>\n",
       "      <th>Done</th>\n",
       "      <th>Local tested .predict from score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">save()</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Done</th>\n",
       "      <th>Conducted Introspect Test</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uploaded artifact to model catalog</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deploy()</th>\n",
       "      <th>ACTIVE</th>\n",
       "      <th>Deployed the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict()</th>\n",
       "      <th>Available</th>\n",
       "      <th>Called deployment predict endpoint</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        Actions Needed\n",
       "Step      Status    Details                                                           \n",
       "initiate  Done      Initiated the model                                               \n",
       "prepare() Done      Generated runtime.yaml                                            \n",
       "                    Generated score.py                                                \n",
       "                    Serialized model                                                  \n",
       "                    Populated metadata(Custom, Taxonomy and Provenance)               \n",
       "verify()  Done      Local tested .predict from score.py                               \n",
       "save()    Done      Conducted Introspect Test                                         \n",
       "                    Uploaded artifact to model catalog                                \n",
       "deploy()  ACTIVE    Deployed the model                                                \n",
       "predict() Available Called deployment predict endpoint                                "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_model.summary_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96fdfeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_onoci_v1_0]",
   "language": "python",
   "name": "conda-env-pytorch_onoci_v1_0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
