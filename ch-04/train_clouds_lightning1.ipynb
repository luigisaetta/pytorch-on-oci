{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "630e9577",
   "metadata": {},
   "source": [
    "### Cloud Classifier based on PyTorch Lightning\n",
    "\n",
    "dataset used from: https://www.kaggle.com/competitions/cloud-type-classification2\n",
    "\n",
    "To execute the notebook you need to download the dataset, from the kaggle competition site, with the command:\n",
    "\n",
    "kaggle competitions download -c cloud-type-classification2\n",
    "\n",
    "and unzip the downloaded file in $BASE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d005599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "# the backbone\n",
    "from torchvision.models import efficientnet_b0\n",
    "\n",
    "sns.set()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1803b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "\n",
    "# for train dataloader.\n",
    "NUM_WORKERS = 12\n",
    "\n",
    "# size of the image we're working on for EffNetB0\n",
    "IMAGE_SIDE = 224\n",
    "\n",
    "# the base_dir inside which we unzip the file from Kaggle\n",
    "BASE_DIR = \"/home/datascience/clouds_classification_data/\"\n",
    "\n",
    "IMAGES_TRAIN = BASE_DIR + \"images/train/\"\n",
    "IMAGES_TEST = BASE_DIR +\"images/test/\"\n",
    "\n",
    "# the file with image_name, label\n",
    "FILE_TRAIN = BASE_DIR + \"train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01c9889d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we read the csv with all file name + labes\n",
    "train_csv_df = pd.read_csv(FILE_TRAIN)\n",
    "\n",
    "# count the number of classes\n",
    "# cirriform clouds,high cumuliform clouds,stratocumulus clouds,cumulus clouds,cumulonimbus clouds,stratiform clouds,clear sky\n",
    "N_CLASSES = train_csv_df['label'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e3d1d8",
   "metadata": {},
   "source": [
    "#### Image trasformations (also for augmentation, applied only to train set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5602adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm using mean and std for ImageNet\n",
    "MEANS = [0.485, 0.456, 0.406]\n",
    "STDS = [0.229, 0.224, 0.225]\n",
    "\n",
    "def get_train_transform():\n",
    "    return T.Compose(\n",
    "        [\n",
    "            T.Resize((IMAGE_SIDE, IMAGE_SIDE)),\n",
    "            T.RandomHorizontalFlip(p=0.5),\n",
    "            T.RandomVerticalFlip(p=0.5),\n",
    "            T.RandomRotation(25),\n",
    "            T.RandomAdjustSharpness(sharpness_factor=1.5, p=0.3),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=MEANS, std=STDS),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# val transforms doesn't make augmentation: we want to validate every time\n",
    "# on the same images\n",
    "def get_val_transform():\n",
    "    return T.Compose(\n",
    "        [\n",
    "            T.Resize((IMAGE_SIDE, IMAGE_SIDE)),\n",
    "            T.ToTensor(), \n",
    "            T.Normalize(mean=MEANS, std=STDS)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cc9714",
   "metadata": {},
   "source": [
    "#### The custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5344b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass as input the train dataframe\n",
    "class CloudsDataset(Dataset):\n",
    "    def __init__(self, df, transforms=None):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        # list with imgs names\n",
    "        self.imgs = df['id'].values\n",
    "        self.labels = df['label'].values\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        full_image_name = IMAGES_TRAIN + self.imgs[idx]\n",
    "        \n",
    "        img = Image.open(full_image_name)\n",
    "        # OK for EfficientNet B0\n",
    "        # if scaling to another EffNet change the size here!\n",
    "        img = self.transforms(img)\n",
    "\n",
    "        # get the label\n",
    "        label = self.labels[idx]\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        \n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd5629b",
   "metadata": {},
   "source": [
    "#### Datasets and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ede9505d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/validation split:\n",
      "We have 864 imgs for training\n",
      "We have 96 imgs for validation\n"
     ]
    }
   ],
   "source": [
    "# split in train and validation\n",
    "# added shuffling (LS, 9/11/2022)\n",
    "\n",
    "# the dataset is small, I'm using only 10% for validation\n",
    "VAL_FRAC = 0.1\n",
    "\n",
    "train_df_used, val_df_used = train_test_split(train_csv_df, shuffle= True, test_size=VAL_FRAC)\n",
    "\n",
    "print(\"Train/validation split:\")\n",
    "print(f\"We have {len(train_df_used)} imgs for training\")\n",
    "print(f\"We have {len(val_df_used)} imgs for validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d23a81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets\n",
    "train_ds = CloudsDataset(train_df_used, transforms=get_train_transform())\n",
    "val_ds = CloudsDataset(val_df_used, transforms=get_val_transform())\n",
    "\n",
    "# data loaders\n",
    "train_dl = DataLoader(\n",
    "    dataset=train_ds, num_workers=NUM_WORKERS, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True\n",
    ")\n",
    "\n",
    "val_dl = DataLoader(\n",
    "    dataset=val_ds, num_workers=NUM_WORKERS, batch_size=BATCH_SIZE, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e513c87",
   "metadata": {},
   "source": [
    "#### The Lightning Model based on EffNetB0\n",
    "\n",
    "we're using the EffNetB0 from TorchVision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "812fd8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitCloudClassifierB0(LightningModule):\n",
    "    def __init__(self, learning_rate=0.0001):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # Set our init args as class attributes\n",
    "        self.lr = learning_rate\n",
    "\n",
    "        # dataset specific attributes\n",
    "        self.num_classes = N_CLASSES\n",
    "        \n",
    "        # Define PyTorch model: a simple CNN\n",
    "        self.model = efficientnet_b0(pretrained=True)\n",
    "        self.model.classifier[1] = nn.Sequential(nn.Linear(1280, self.num_classes, bias=True))\n",
    "\n",
    "        self.val_accuracy = Accuracy()\n",
    "        self.test_accuracy = Accuracy()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # the model outputs logits not probabilities\n",
    "        # this is better for numerical stability\n",
    "        x = self.model(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.val_accuracy.update(preds, y)\n",
    "\n",
    "        # Calling self.log will surface up scalars for you in TensorBoard\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", self.val_accuracy, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.test_accuracy.update(preds, y)\n",
    "\n",
    "        # Calling self.log will surface up scalars for you in TensorBoard\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "        self.log(\"test_acc\", self.test_accuracy, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # for now fixed LR\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        \n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92f8d50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(dirpath=\"checkpoint_clouds\", save_top_k=1, monitor=\"val_loss\",\n",
    "                                     mode=\"min\",\n",
    "                                     filename=\"clouds-{epoch:02d}-{val_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a30e088",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "model = LitCloudClassifierB0()\n",
    "\n",
    "trainer = Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    # we can choose to use mixed precision, to reduce mem. footprint\n",
    "    precision=16,\n",
    "    devices=1 if torch.cuda.is_available() else None,\n",
    "    max_epochs=EPOCHS,\n",
    "    callbacks=[TQDMProgressBar(refresh_rate=5), checkpoint_callback],\n",
    "    logger=CSVLogger(save_dir=\"logs/\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c35548f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type         | Params\n",
      "-----------------------------------------------\n",
      "0 | model         | EfficientNet | 4.0 M \n",
      "1 | val_accuracy  | Accuracy     | 0     \n",
      "2 | test_accuracy | Accuracy     | 0     \n",
      "-----------------------------------------------\n",
      "4.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.0 M     Total params\n",
      "8.033     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80b916bfb8874978b270c23dfe4f8fd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model, train_dl, val_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b797ce",
   "metadata": {},
   "source": [
    "#### Plot metrics during the epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "97795fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 442.85x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get metrics from the logs\n",
    "metrics = pd.read_csv(f\"{trainer.logger.log_dir}/metrics.csv\")\n",
    "del metrics[\"step\"]\n",
    "metrics.set_index(\"epoch\", inplace=True)\n",
    "\n",
    "# if you want also in tabular format\n",
    "# display(metrics.dropna(axis=1, how=\"all\").tail(10))\n",
    "\n",
    "sns.relplot(data=metrics, kind=\"line\").set(title='Metrics for val set');\n",
    "plt.grid(True)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183d6a0a",
   "metadata": {},
   "source": [
    "#### Test: reload the Best Model and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a5bc8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put here the name of the best checkpoint file\n",
    "model = LitCloudClassifierB0.load_from_checkpoint(\"./checkpoint_clouds/best11092022.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ded42612",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e845a388c2b74496b87567e068ce4d4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc                  0.96875\n",
      "        test_loss           0.13714081048965454\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.13714081048965454, 'test_acc': 0.96875}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, val_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84630f8",
   "metadata": {},
   "source": [
    "#### let's see the errors on the entire validation set\n",
    "\n",
    "could be imrpoved using batch, but since val_set is smal it is ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4e1b74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 33/96 [00:08<00:17,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: 2, predicted: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 71/96 [00:18<00:05,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: 5, predicted: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 76/96 [00:20<00:05,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: 2, predicted: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [00:25<00:00,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tot. OK: 93 over: 96\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_test = len(val_ds)\n",
    "n_ok = 0\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "for i in tqdm(range(n_test)):\n",
    "    img, label = val_ds[i]\n",
    "\n",
    "    img_batch = img.unsqueeze(0)\n",
    "    img_batch = img_batch.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        preds = model(img_batch)\n",
    "\n",
    "    class_predicted = torch.argmax(preds, dim=1)\n",
    "    \n",
    "    # otherwise are tensors\n",
    "    label = label.item()\n",
    "    class_predicted = class_predicted.item()\n",
    "    \n",
    "    if class_predicted == label:\n",
    "        n_ok += 1\n",
    "    else:\n",
    "        print(f\"Expected: {label}, predicted: {class_predicted}\")\n",
    "        \n",
    "print()\n",
    "print(f\"Tot. OK: {n_ok} over: {n_test}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc2898b",
   "metadata": {},
   "source": [
    "#### Prepare Submission for Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "adec29f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_TEST = BASE_DIR +\"images/test/\"\n",
    "FILE_TEST = BASE_DIR + \"test.csv\"\n",
    "\n",
    "test_df = pd.read_csv(FILE_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "24d078cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_imgs = list(test_df['id'].values)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "568e4150",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### here we create a custom dataset for test (no labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "03ffa357",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CloudsTestDataset(Dataset):\n",
    "    def __init__(self, df, transforms=None):\n",
    "        super().__init__()\n",
    "        # list with imgs names\n",
    "        self.imgs = df['id'].values\n",
    "        self.df = df\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        full_image_name = IMAGES_TEST + self.imgs[idx]\n",
    "        \n",
    "        img = Image.open(full_image_name)\n",
    "        # OK for EfficientNet B0\n",
    "        # if scaling to another EffNet change the size here!\n",
    "        img = self.transforms(img)\n",
    "        \n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c2d11833",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = CloudsTestDataset(test_df, transforms=get_val_transform())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d05216",
   "metadata": {},
   "source": [
    "#### Predictions for all test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed58cf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 700/700 [02:25<00:00,  4.80it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "list_preds = []\n",
    "\n",
    "for i in tqdm(range(len(test_ds))):\n",
    "    img = test_ds[i]\n",
    "\n",
    "    img_batch = img.unsqueeze(0)\n",
    "    img_batch = img_batch.to(device)\n",
    "    \n",
    "    preds = model(img_batch)\n",
    "\n",
    "    class_predicted = torch.argmax(preds)\n",
    "    class_predicted = class_predicted.item()\n",
    "    \n",
    "    list_preds.append(class_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccae0c7a",
   "metadata": {},
   "source": [
    "#### Get a file with the class_num for each jpg image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d57cfad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_sub = {\"id\": test_imgs, \n",
    "           \"predict\": list_preds}\n",
    "\n",
    "df_sub = pd.DataFrame(dict_sub)\n",
    "\n",
    "df_sub.to_csv(\"submit04.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c443be82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:computervision_p37_gpu_v1]",
   "language": "python",
   "name": "conda-env-computervision_p37_gpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
