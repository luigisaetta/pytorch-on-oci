{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "662c8778",
   "metadata": {},
   "source": [
    "### Cloud Classifier based on PyTorch Lightning\n",
    "\n",
    "dataset used from: https://www.kaggle.com/competitions/cloud-type-classification2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0957650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchmetrics import Accuracy\n",
    "# the backbone\n",
    "from torchvision.models import efficientnet_b0\n",
    "\n",
    "sns.set()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46f02e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "\n",
    "# for train dataloader.\n",
    "NUM_WORKERS = 12\n",
    "\n",
    "# size of the image we're working on\n",
    "# fit for EffNetB0\n",
    "IMAGE_SIDE = 224\n",
    "\n",
    "DIR_TRAIN = \"./images/train/\"\n",
    "\n",
    "# number of different clouds types\n",
    "N_CLASSES = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f3203c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we read the csv\n",
    "train_csv_df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35e4a19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm using mean and std for ImageNet\n",
    "MEANS = [0.485, 0.456, 0.406]\n",
    "STDS = [0.229, 0.224, 0.225]\n",
    "\n",
    "def get_train_transform():\n",
    "    return T.Compose(\n",
    "        [\n",
    "            T.Resize((IMAGE_SIDE, IMAGE_SIDE)),\n",
    "            T.RandomHorizontalFlip(p=0.5),\n",
    "            T.RandomVerticalFlip(p=0.5),\n",
    "            T.RandomRotation(25),\n",
    "            T.RandomAdjustSharpness(sharpness_factor=1.5, p=0.3),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=MEANS, std=STDS),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# val transforms doesn't make augmentation: we want to validate every time\n",
    "# on the same images\n",
    "def get_val_transform():\n",
    "    return T.Compose(\n",
    "        [\n",
    "            T.Resize((IMAGE_SIDE, IMAGE_SIDE)),\n",
    "            T.ToTensor(), \n",
    "            T.Normalize(mean=MEANS, std=STDS)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "652ba268",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CloudsDataset(Dataset):\n",
    "    def __init__(self, df, transforms=None):\n",
    "        super().__init__()\n",
    "        # list with imgs names\n",
    "        self.imgs = df['id'].values\n",
    "        self.df = df\n",
    "        self.labels = df['label'].values\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        full_image_name = DIR_TRAIN + self.imgs[idx]\n",
    "        \n",
    "        img = Image.open(full_image_name)\n",
    "        # OK for EfficientNet B0\n",
    "        # if scaling to another EffNet change the size here!\n",
    "        img = self.transforms(img)\n",
    "\n",
    "        # get the label\n",
    "        label = self.labels[idx]\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        \n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de3d001",
   "metadata": {},
   "source": [
    "#### Datasets and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e99f3c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 864 imgs for training\n",
      "We have 96 imgs for validation\n"
     ]
    }
   ],
   "source": [
    "# split in train and validation\n",
    "# added shuffling (LS, 9/11/2022)\n",
    "train_df_used, val_df_used = train_test_split(train_csv_df, shuffle= True, test_size=0.10)\n",
    "\n",
    "print(f\"We have {len(train_df_used)} imgs for training\")\n",
    "print(f\"We have {len(val_df_used)} imgs for validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24c0d60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets\n",
    "train_ds = CloudsDataset(train_df_used, transforms=get_train_transform())\n",
    "val_ds = CloudsDataset(val_df_used, transforms=get_val_transform())\n",
    "\n",
    "# data loaders\n",
    "train_dl = DataLoader(\n",
    "    dataset=train_ds, num_workers=NUM_WORKERS, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True\n",
    ")\n",
    "\n",
    "val_dl = DataLoader(\n",
    "    dataset=val_ds, num_workers=NUM_WORKERS, batch_size=BATCH_SIZE, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bf45bb",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "773d04d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitCloudClassifierB0(LightningModule):\n",
    "    def __init__(self, learning_rate=0.0001):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # Set our init args as class attributes\n",
    "        self.lr = learning_rate\n",
    "\n",
    "        # dataset specific attributes\n",
    "        self.num_classes = N_CLASSES\n",
    "        \n",
    "        # Define PyTorch model: a simple CNN\n",
    "        self.model = efficientnet_b0(pretrained=True)\n",
    "        self.model.classifier[1] = nn.Sequential(nn.Linear(1280,self.num_classes, bias=True))\n",
    "\n",
    "        self.val_accuracy = Accuracy()\n",
    "        self.test_accuracy = Accuracy()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # the model outputs logits not probabilities\n",
    "        # this is better for numerical stability\n",
    "        x = self.model(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.val_accuracy.update(preds, y)\n",
    "\n",
    "        # Calling self.log will surface up scalars for you in TensorBoard\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", self.val_accuracy, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.test_accuracy.update(preds, y)\n",
    "\n",
    "        # Calling self.log will surface up scalars for you in TensorBoard\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "        self.log(\"test_acc\", self.test_accuracy, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # for now fixed LR\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        \n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e1d6dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(dirpath=\"checkpoint_clouds\", save_top_k=2, monitor=\"val_loss\",\n",
    "                                     mode=\"min\",\n",
    "                                     filename=\"clouds-{epoch:02d}-{val_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba59ae42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "model = LitCloudClassifierB0()\n",
    "\n",
    "trainer = Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    # we can choose to use mixed precision, to reduce mem. footprint\n",
    "    precision=16,\n",
    "    devices=1 if torch.cuda.is_available() else None,\n",
    "    max_epochs=EPOCHS,\n",
    "    callbacks=[TQDMProgressBar(refresh_rate=5), checkpoint_callback],\n",
    "    logger=CSVLogger(save_dir=\"logs/\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21684f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/datascience/conda/computervision_p37_gpu_v1/lib/python3.7/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:606: UserWarning: Checkpoint directory /home/datascience/clouds_recognition/checkpoint_clouds exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type         | Params\n",
      "-----------------------------------------------\n",
      "0 | model         | EfficientNet | 4.0 M \n",
      "1 | val_accuracy  | Accuracy     | 0     \n",
      "2 | test_accuracy | Accuracy     | 0     \n",
      "-----------------------------------------------\n",
      "4.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.0 M     Total params\n",
      "8.033     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eaee0eedca54a1baca5f25daaf6e8f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e86d1f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 442.85x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = pd.read_csv(f\"{trainer.logger.log_dir}/metrics.csv\")\n",
    "del metrics[\"step\"]\n",
    "metrics.set_index(\"epoch\", inplace=True)\n",
    "\n",
    "# if you want also in tabular format\n",
    "# display(metrics.dropna(axis=1, how=\"all\").tail(10))\n",
    "sns.relplot(data=metrics, kind=\"line\").set(title='Metrics');\n",
    "plt.grid(True)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb479d3",
   "metadata": {},
   "source": [
    "#### Reload the Best Model and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "869d8e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitCloudClassifierB0.load_from_checkpoint(\"./checkpoint_clouds/best6_09112022.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "000123aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb7cd88e2df8405a9fa14c12d63d882a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.9583333134651184\n",
      "        test_loss           0.15556417405605316\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.15556417405605316, 'test_acc': 0.9583333134651184}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, val_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5751c563",
   "metadata": {},
   "source": [
    "#### let's see the errors on all validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6badb3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = len(val_ds)\n",
    "n_ok = 0\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "for i in tqdm(range(n_test)):\n",
    "    img, label = val_ds[i]\n",
    "\n",
    "    img_batch = img.unsqueeze(0)\n",
    "    img_batch = img_batch.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        preds = model(img_batch)\n",
    "\n",
    "    class_predicted = torch.argmax(preds, dim=1)\n",
    "    \n",
    "    # otherwise are tensors\n",
    "    label = label.item()\n",
    "    class_predicted = class_predicted.item()\n",
    "    \n",
    "    if class_predicted == label:\n",
    "        n_ok += 1\n",
    "    else:\n",
    "        print(f\"Expected: {label}, predicted: {class_predicted}\")\n",
    "        \n",
    "print()\n",
    "print(f\"Tot. OK: {n_ok} over: {n_test}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37ecede",
   "metadata": {},
   "source": [
    "#### Prepare Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6324f966",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_TEST = \"./images/test/\"\n",
    "\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99104ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs = list(test_df['id'].values)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44e688ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CloudsTestDataset(Dataset):\n",
    "    def __init__(self, df, transforms=None):\n",
    "        super().__init__()\n",
    "        # list with imgs names\n",
    "        self.imgs = df['id'].values\n",
    "        self.df = df\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        full_image_name = DIR_TEST + self.imgs[idx]\n",
    "        \n",
    "        img = Image.open(full_image_name)\n",
    "        # OK for EfficientNet B0\n",
    "        # if scaling to another EffNet change the size here!\n",
    "        img = self.transforms(img)\n",
    "        \n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c2fe2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = CloudsTestDataset(test_df, transforms=get_val_transform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29082272",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "list_preds = []\n",
    "\n",
    "for i in tqdm(range(len(test_ds))):\n",
    "    img = test_ds[i]\n",
    "\n",
    "    img_batch = img.unsqueeze(0)\n",
    "    img_batch = img_batch.to(device)\n",
    "    \n",
    "    preds = model(img_batch)\n",
    "\n",
    "    class_predicted = torch.argmax(preds)\n",
    "    class_predicted = class_predicted.item()\n",
    "    \n",
    "    list_preds.append(class_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e195c784",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_sub = {\"id\": test_imgs, \n",
    "           \"predict\": list_preds}\n",
    "\n",
    "df_sub = pd.DataFrame(dict_sub)\n",
    "\n",
    "df_sub.to_csv(\"submit03.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e1a99b",
   "metadata": {},
   "source": [
    "#### EDA on val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d96d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "cases_count = val_df_used['label'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.barplot(x=cases_count.index, y= cases_count.values)\n",
    "plt.title('Number of images', fontsize=14)\n",
    "plt.xlabel('class', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xticks(range(len(cases_count.index)), ['0', '1', '2', '3', '4', '5', '6'])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61353899",
   "metadata": {},
   "source": [
    "#### New tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fd54ea9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CloudsNewTestDataset(Dataset):\n",
    "    def __init__(self, df, transforms=None):\n",
    "        super().__init__()\n",
    "        # list with imgs names\n",
    "        self.imgs = df['id'].values\n",
    "        self.df = df\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.imgs[idx]\n",
    "        full_image_name = DIR_TEST + img_name\n",
    "        \n",
    "        img = Image.open(full_image_name)\n",
    "        # OK for EfficientNet B0\n",
    "        # if scaling to another EffNet change the size here!\n",
    "        img = self.transforms(img)\n",
    "        \n",
    "        return img, img_name\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1e400881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clear_sky1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cum_nembo2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>strato_cumulus1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>normal1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cirr2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>new_cirro1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cum_nembo1.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id\n",
       "0       clear_sky1.jpg\n",
       "1       cum_nembo2.jpg\n",
       "2  strato_cumulus1.jpg\n",
       "3          normal1.jpg\n",
       "4            cirr2.jpg\n",
       "5       new_cirro1.jpg\n",
       "6       cum_nembo1.jpg"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "# this way I can easily add new images for test\n",
    "list_new_imgs = [os.path.basename(path) for path in glob.glob(\"./*.jpg\")]\n",
    "\n",
    "DIR_TEST = \"./\"\n",
    "dict_new_tests = {\"id\": list_new_imgs}\n",
    "\n",
    "df_new_tests = pd.DataFrame(dict_new_tests)\n",
    "\n",
    "df_new_tests.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "32e0d0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_ds = CloudsNewTestDataset(df_new_tests, transforms=get_val_transform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2dd9a839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clear_sky1.jpg, predicted: 6\n",
      "cum_nembo2.jpg, predicted: 4\n",
      "strato_cumulus1.jpg, predicted: 4\n",
      "normal1.jpg, predicted: 4\n",
      "cirr2.jpg, predicted: 0\n",
      "new_cirro1.jpg, predicted: 0\n",
      "cum_nembo1.jpg, predicted: 3\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "for i in range(len(new_test_ds)):\n",
    "    img, img_name = new_test_ds[i]\n",
    "\n",
    "    img_batch = img.unsqueeze(0)\n",
    "    img_batch = img_batch.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        preds = model(img_batch)\n",
    "\n",
    "    class_predicted = torch.argmax(preds, dim=1)\n",
    "        \n",
    "    print(f\"{img_name}, predicted: {class_predicted.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a710b3ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:computervision_p37_gpu_v1]",
   "language": "python",
   "name": "conda-env-computervision_p37_gpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
