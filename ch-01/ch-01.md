# Capitolo 1

## Introduzione.

## Creazione di un ambiente PyTorch

Il primo passo da compiere per utilizzare PyTorch in OCI Data Science è di creare una Notebook Session.
La **Notebook Session** la possiamo pensare come una macchina virtuale (VM), con il numero di core, la memoria e 
lo spazio di memorizzazione specificati all'atto della creazione (la sua "shape").

In realtà, si tratta di un'infrastruttura più complessa, che fornisce una serie di funzionalità aggiuntive e di benefici, rispetto ad 
una VM custom.
La VM tipicamente (è una best practice) è collocata su una subnet privata. L'accesso tramite questa subnet è utilizzato per il traffico "outbound", ovvero 
per le richieste in uscita dalla VM. Esempio: l'accesso agli altri servizi Cloud (come l'Object Storage) oppure le fonti di dati (un Autonomous DWH).
L'accesso in ingresso, per utilizzare tramite Browser l'interfaccia tipica di **Jupyter**, avviene attraverso una serie di layer, gestiti da Oracle, che garantiscono la sicurezza (possiamo immagine LB, proxy, ..).
Inolre, una Notebook Session è un servizio **Oracle Managed**. Non dobbiamo preoccuparci di monitorarlo, di garantire che sia up&running nel rispetto dei Livelli di Servizio (SLA) contrattuali. Ci pensano le Cloud Operations Oracle.

Nel momento in cui creaimo la Notebook Session abbiamo una scelta abbastanza ampia. Possiamo crearla in prima istanza con pochi core e poi, semplicemente disattivando e riattivando con un'altra shape, aumentare la capacità di calcolo a disposizione, quando necessario.

Negli esempi che mostro, spesso utilizzerò una **GPU** per velocizzare le elaborazione. La shape che quindi ho scelto è una **VMGPU2.1**, equipaggiata con una GPU economica (P100) ma sufficiente per molti dei casi che illustrerò.

Dopo aver creato la Notebook Session il passo successivo da compiere è di creare l'ambiente software.
Il package manager utilizzato è Anaconda (conda).
Creare un ambiente integrato, con centinaia di librerie a disposizione, di versioni compatibili, non è per nulla un'operazione semplice.
Ma, a ciò ha pensato il team di Oracle Data Science, che mette a disposizione, pronti da installare, più di **45 ambienti conda** (ed il numero cresce mese per mese).

L'ambiente che ho selezionato per i miei primi esempi è l'ambiente: **PyTorch 1.10 for GPU on Python 3.7**.
Preciso che tale abiente, pur mettendo a disposizione le librerie dell'ecosistema PyTorch integrate con le CUDA di NVIDIA, può essere utilizzato anche all'interno di una
NB session senza GPU.

Dall'Environment Explorer posso copiare il comando che consente di installare tale ambiente:

```
odsc conda install -s pytorch110_p37_gpu_v1 
```

e poi possiamo eseguire tale comando in una finestra di terminale (io preferisco per tali operazioni la command line).

L'installazione dura poco, circa tre minuti. Dopo i quali possiamo attivare nella finestra di terminale l'ambiente con il comando (che è visualizzato al
termine dell'installazione):

```
conda activate /home/datascience/conda/pytorch110_p37_gpu_v1
```

## Un primo test dell'ambiente PyTorch

A questo punto siamo pronti per un primo test dell'ambiente. Io suggerisco sempre, prima di lanciarsi nello sviluppo di un modello complesso di rete neurale, di effettuare un semplice check-up dell'ambiente.

Ho preparato un Notebook che può aiutare nello scopo. Nell'ordine:
* visualizza la versione di PyTorch installata (alo stato attuale, la vers. 1.10)
* controlla che l'integrazione con le CUDA sia funzionante
* controlla il numero di GPU (nel caso della VMGPU2.1 1 GPU)
* visualizza altre utili informazioni, tramite il comando nvidia-smi

Ecco il [link](./check_pytorch_and_gpu.ipynb).






